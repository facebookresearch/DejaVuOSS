{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dejavuoob.utils.image_common import ImageFolderIndexWithPath, SSL_Transform\n",
    "from dejavuoob.utils.common import most_conf_frac\n",
    "from scipy import stats\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_and_topk(neighb_labels, k_neighbs = 100, topk = [1]):\n",
    "    from scipy.stats import entropy\n",
    "    import torch\n",
    "\n",
    "    #get class counts\n",
    "    class_cts = np.apply_along_axis(np.bincount, axis=1,\n",
    "                            arr=neighb_labels[:,:k_neighbs], minlength=1000)\n",
    "\n",
    "    #get confidence\n",
    "    attk_uncert = entropy(class_cts, axis = 1)\n",
    "    preds = {}\n",
    "    preds_values = {}\n",
    "    for k in topk:\n",
    "        topk_cts, topk_preds = torch.topk(torch.Tensor(class_cts), k, dim = 1)\n",
    "        topk_preds = np.array(topk_preds).astype(int)\n",
    "        preds[f'top_{k}'] = topk_preds\n",
    "        preds_values[f'top[k]'] = topk_cts\n",
    "\n",
    "    return -attk_uncert, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139183"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VICREG_KNN_ROOT_PATH_MEM_OOB = '<PATH-VICREG-OUTPUT>/dejavu/vicreg/attack_sweeps/NN_attk_vicregoob_model_bbox_A_bbox_B_blurred_05.11.2024'\n",
    "\n",
    "vicreg_bbox_attk_B_idxs_mem_oob = np.load(VICREG_KNN_ROOT_PATH_MEM_OOB + '/valid_attk_A_attk_idxs.npy')\n",
    "vicreg_bbox_attk_B_labels_mem_oob = np.load(VICREG_KNN_ROOT_PATH_MEM_OOB + '/valid_attk_A_labels.npy')\n",
    "vicreg_bbox_attk_B_neighb_labels_mem_oob = np.load(VICREG_KNN_ROOT_PATH_MEM_OOB + '/valid_attk_A_neighb_labels.npy')\n",
    "vicreg_bbox_attk_B_neighb_idx_mem_oob = np.load(VICREG_KNN_ROOT_PATH_MEM_OOB + '/valid_attk_A_neighb_idxs.npy')\n",
    "\n",
    "len(vicreg_bbox_attk_B_labels_mem_oob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset mem oob\n",
    "img_dir = '<PATH-TO-IMAGENET-TRAIN>/train_blurred'\n",
    "vicreg_dataset = ImageFolderIndexWithPath(img_dir, SSL_Transform(), vicreg_bbox_attk_B_idxs_mem_oob)\n",
    "vicreg_dataloader_mem_oob = DataLoader(vicreg_dataset, batch_size = 1, shuffle = False, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vicreg_confidences_mem_oob, vicreg_pred_idxes_mem_oob = get_confidence_and_topk(vicreg_bbox_attk_B_neighb_labels_mem_oob)\n",
    "\n",
    "vicreg_confidences_mem_oob, vicreg_pred_idxes_mem_oob = vicreg_confidences_mem_oob, vicreg_pred_idxes_mem_oob['top_1']\n",
    "\n",
    "\n",
    "predictions_to_save = []\n",
    "for (x, y, idx, path), label, confidence, pred in zip(vicreg_dataloader_mem_oob, vicreg_bbox_attk_B_labels_mem_oob, vicreg_confidences_mem_oob, vicreg_pred_idxes_mem_oob):\n",
    "    predictions_to_save.append([idx.item(), label[0], pred[0], confidence, path[0]])\n",
    "columns = ['idx_vmo', 'label_vmo', 'pred_vmo', 'conf_vmo', 'path_vmo']\n",
    "\n",
    "vicreg_predictions_knn_mem_oob = pd.DataFrame.from_records(np.array(predictions_to_save), columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vicreg_predictions_knn_mem_oob_srt = vicreg_predictions_knn_mem_oob.sort_values(by = ['path_vmo'], ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_resnet = np.load('<PATH-RESNET-OUTPUT>/dejavu/resnet50_crops/eval/supervised_train_A_test_B_set_15_05_2024_wd_0.1_lars_mom_0.9_w_aug_eval.npy')\n",
    "columns = ['label', 'pred', 'conf', 'path']\n",
    "\n",
    "predictions_resnet = pd.DataFrame.from_records(np.array(predictions_resnet), columns=columns)\n",
    "predictions_resnet['path'] = predictions_resnet['path'].str.split('/').str[-1].str.split('.').str[0]\n",
    "predictions_resnet_srt = predictions_resnet.sort_values(by = ['path'], ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_resnet2 = np.load('<PATH-RESNET-OUTPUT2>/dejavu/resnet50_crops/eval/supervised_train_A_test_B_set_07_11_2024_wd_0.1_lars_mom_0.9_w_aug_eval.npy')\n",
    "columns = ['label2', 'pred2', 'conf2', 'path2']\n",
    "predictions_resnet2 = pd.DataFrame.from_records(np.array(predictions_resnet2), columns=columns)\n",
    "predictions_resnet2['path2'] = predictions_resnet2['path2'].str.split('/').str[-1].str.split('.').str[0]\n",
    "predictions_resnet2_srt = predictions_resnet2.sort_values(by = ['path2'], ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "imagenet_label_path = '<PATH-IMAGENET-LABELS>/labels.txt'\n",
    "nb_output_path = '<HOME-GROUNDED-SEGANY>/Grounded-Segment-Anything/output_May_03_2023_trainA_testB'\n",
    "class_id2index = {}\n",
    "classes = []\n",
    "\n",
    "with open(imagenet_label_path) as folder2label:\n",
    "    folder2label_reader = csv.reader(folder2label, delimiter=',')\n",
    "    folder2label_lst = [line for line in folder2label_reader]\n",
    "    file_names_all = []\n",
    "    prediction_scores_all = []\n",
    "    prediction_label_all = []\n",
    "    targets_all = []\n",
    "    for i, folder2label in enumerate(folder2label_lst):\n",
    "        class_id, class_name = folder2label\n",
    "        class_id2index[class_id] = i\n",
    "        labels_input_path = os.path.join(nb_output_path, 'predictions_top_5_before_Aug_2nd', f'{class_id}_{class_name}_predictions.json')\n",
    "        labels_input = json.loads(open(labels_input_path).read())\n",
    "        file_names = labels_input.keys()\n",
    "        predictions = labels_input.values()\n",
    "        prediction_scores = [prediction[0] for prediction in predictions]\n",
    "        prediction_label = [prediction[1] for prediction in predictions]\n",
    "        targets = [f'{class_id}_{class_name}'] * len(predictions)\n",
    "        classes.append(class_name)\n",
    "\n",
    "        file_names_all.append(file_names)\n",
    "        prediction_scores_all.append(prediction_scores)\n",
    "        prediction_label_all.append(prediction_label)\n",
    "        targets_all.append(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139183"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names_all = list(flatten(file_names_all))\n",
    "prediction_scores_all = list(flatten(prediction_scores_all))\n",
    "prediction_label_all = list(flatten(prediction_label_all))\n",
    "targets_all = list(flatten(targets_all))\n",
    "len(targets_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139183, 139183)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets_all), len(file_names_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['label_n', 'pred_n', 'conf_n', 'path_n']\n",
    "\n",
    "predictions_nb = pd.DataFrame({'label_n': targets_all, 'pred_n': prediction_label_all, 'conf_n': prediction_scores_all, 'path_n': file_names_all})\n",
    "\n",
    "predictions_nb['label_n'] = predictions_nb['label_n'].str.split('_').str[0].apply(lambda x: class_id2index[x])\n",
    "predictions_nb['pred_n'] = predictions_nb['pred_n'].str.split('_').str[0].apply(lambda x: class_id2index[x])\n",
    "predictions_nb['path_n'] = predictions_nb['path_n'].str.split('.').str[0]\n",
    "\n",
    "predictions_nb_srt = predictions_nb.sort_values(by = ['path_n'], ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vicreg_predictions_knn_mem_oob_srt['path_vmo'] = vicreg_predictions_knn_mem_oob_srt['path_vmo'].str.split('/').str[-1].str.split('.').str[0]\n",
    "result = pd.merge(vicreg_predictions_knn_mem_oob_srt, predictions_resnet_srt, how=\"inner\", left_on = 'path_vmo', right_on='path')\n",
    "\n",
    "result = pd.merge(result, predictions_resnet2_srt, how=\"inner\", left_on = 'path', right_on='path2')\n",
    "result = pd.merge(result, predictions_nb_srt, how=\"inner\", left_on = 'path', right_on='path_n')\n",
    "\n",
    "cond6 = result['pred'] == result['label']\n",
    "result = result[cond6]\n",
    "\n",
    "cond7 = result['pred2'] == result['label2']\n",
    "result = result[cond7]\n",
    "\n",
    "cond8 = result['pred_n'] == result['label_n']\n",
    "result = result[cond8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_idx = np.array(list(result['idx_vmo']), dtype=int)  # convert string to int and load this the images based on this ids. Visualize some of them.\n",
    "\n",
    "img_dir = '<PATH-TO-IMAGENET-TRAIN>/train_blurred'\n",
    "corr_dataset = ImageFolderIndexWithPath(img_dir, SSL_Transform(), corr_idx)\n",
    "corr_dataset_mem_oob = DataLoader(corr_dataset, batch_size = 1, shuffle = False, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('DejaVuOOB/data/dataset_level_correlations_indices.npy', corr_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class InverseTransform:\n",
    "    \"\"\"inverses normalization of SSL transform \"\"\"\n",
    "    def __init__(self): \n",
    "        self.invTrans = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "        std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "        torchvision.transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "        std = [ 1., 1., 1. ]),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x): \n",
    "        return self.invTrans(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "iTrans = InverseTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(image, label):\n",
    "    print('label:', label)\n",
    "    print('image shape: ', image.shape)\n",
    "    patch = iTrans(image.squeeze())\n",
    "    patch = patch.permute(1,2,0)        \n",
    "    plt.imshow(patch)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i, (x, y, idx, path) in enumerate(corr_dataset_mem_oob):\\n    print(path)\\n    showImg(x, y)\\n    if i > 30:\\n        break\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i, (x, y, idx, path) in enumerate(corr_dataset_mem_oob):\n",
    "    print(path)\n",
    "    showImg(x, y)\n",
    "    if i > 30:\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dejavuoob3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
